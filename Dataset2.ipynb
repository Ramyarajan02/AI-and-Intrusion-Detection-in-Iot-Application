{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gEBcmjeqs04L",
        "outputId": "c49b037e-f50e-48c8-8d58-f46b2e606678"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ML Model Accuracy: 98.82%\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['label_encoder.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import joblib\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv('/content/kdd_test.csv')  # or your full dataset\n",
        "df.columns = [f\"col_{i}\" for i in range(len(df.columns)-1)] + ['label']\n",
        "\n",
        "# Keep copy of original label\n",
        "df['attack_type'] = df['label']\n",
        "\n",
        "# Encode categorical columns\n",
        "for col in df.select_dtypes(include='object').columns:\n",
        "    if col != 'label':\n",
        "        le = LabelEncoder()\n",
        "        df[col] = le.fit_transform(df[col])\n",
        "\n",
        "# Convert label to 'attack' or 'normal'\n",
        "df['label'] = df['label'].apply(lambda x: 'normal' if 'normal' in x else 'attack')\n",
        "\n",
        "# Encode label\n",
        "label_encoder = LabelEncoder()\n",
        "df['label'] = label_encoder.fit_transform(df['label'])\n",
        "\n",
        "# Split data\n",
        "X = df.drop(['label', 'attack_type'], axis=1)\n",
        "y = df['label']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Train model\n",
        "model = RandomForestClassifier()\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Evaluate accuracy on test data\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"ML Model Accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "# Save everything\n",
        "joblib.dump(model, 'ml_model.pkl')\n",
        "joblib.dump(scaler, 'scaler.pkl')\n",
        "joblib.dump(label_encoder, 'label_encoder.pkl')\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load your dataset\n",
        "df = pd.read_csv('/content/kdd_test.csv')  # replace with your file path\n",
        "\n",
        "# Reduce to 1000 rows randomly\n",
        "df_reduced = df.sample(n=1000, random_state=42)  # random_state for reproducibility\n",
        "\n",
        "# Save the reduced dataset\n",
        "df_reduced.to_csv('testing_dataset.csv', index=False)\n"
      ],
      "metadata": {
        "id": "eX41nqZGRCO6"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XflWHVtUuh9z",
        "outputId": "dad7ba0d-0c81-4b64-cdbf-c4d7759d76a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔍 ML Predictions on 3 Random Samples:\n",
            "Sample 1: ✅ Normal | Attack Type: normal\n",
            "Sample 2: ✅ Normal | Attack Type: normal\n",
            "Sample 3: ❌ Attack Detected | Attack Type: warezclient\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import joblib\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Load the testing dataset\n",
        "df = pd.read_csv('/content/testing_dataset.csv')\n",
        "df.columns = [f\"col_{i}\" for i in range(len(df.columns)-1)] + ['label']\n",
        "\n",
        "# ✅ Store original attack names before any encoding\n",
        "original_attacks = df['label'].values.copy()\n",
        "\n",
        "# Encode categorical columns (skip label for now)\n",
        "for col in df.select_dtypes(include='object').columns:\n",
        "    if col != 'label':\n",
        "        le = LabelEncoder()\n",
        "        df[col] = le.fit_transform(df[col])\n",
        "\n",
        "# Binary label: 'normal' or 'attack'\n",
        "df['label'] = df['label'].apply(lambda x: 'normal' if 'normal' in x else 'attack')\n",
        "\n",
        "# Load saved objects\n",
        "label_encoder = joblib.load('label_encoder.pkl')\n",
        "scaler = joblib.load('scaler.pkl')\n",
        "ml_model = joblib.load('ml_model.pkl')\n",
        "\n",
        "# Encode 'label' column: normal=1, attack=0\n",
        "df['label'] = label_encoder.transform(df['label'])\n",
        "\n",
        "# Prepare feature set\n",
        "X_test = df.drop(['label'], axis=1)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# 🎯 Select 3 random samples\n",
        "sample_df = df.sample(n=3, random_state=42)\n",
        "sample_indices = sample_df.index\n",
        "sample_X_scaled = X_test_scaled[sample_indices]\n",
        "\n",
        "# Predict\n",
        "sample_preds = ml_model.predict(sample_X_scaled)\n",
        "sample_attack_names = original_attacks[sample_indices]  # ✅ Use real names\n",
        "\n",
        "# 🖨️ Display results\n",
        "print(\"\\n🔍 ML Predictions on 3 Random Samples:\")\n",
        "for i, (pred, attack_name) in enumerate(zip(sample_preds, sample_attack_names)):\n",
        "    status = \"✅ Normal\" if pred == 1 else \"❌ Attack Detected\"\n",
        "    print(f\"Sample {i+1}: {status} | Attack Type: {attack_name}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jx85iOlaue3D"
      },
      "source": [
        "**DEEP LEARNING**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7sVJGcFRs5Lq",
        "outputId": "cf32ac66-1895-4db0-eed6-06f5a5fdef90"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.8278 - loss: 0.3659 - val_accuracy: 0.9315 - val_loss: 0.1523\n",
            "Epoch 2/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9315 - loss: 0.1591 - val_accuracy: 0.9515 - val_loss: 0.1171\n",
            "Epoch 3/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9519 - loss: 0.1210 - val_accuracy: 0.9556 - val_loss: 0.0991\n",
            "Epoch 4/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9579 - loss: 0.1056 - val_accuracy: 0.9673 - val_loss: 0.0938\n",
            "Epoch 5/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9614 - loss: 0.1018 - val_accuracy: 0.9665 - val_loss: 0.0865\n",
            "Epoch 6/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9611 - loss: 0.0994 - val_accuracy: 0.9673 - val_loss: 0.0843\n",
            "Epoch 7/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9683 - loss: 0.0803 - val_accuracy: 0.9698 - val_loss: 0.0810\n",
            "Epoch 8/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9692 - loss: 0.0845 - val_accuracy: 0.9695 - val_loss: 0.0788\n",
            "Epoch 9/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9676 - loss: 0.0844 - val_accuracy: 0.9753 - val_loss: 0.0775\n",
            "Epoch 10/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9695 - loss: 0.0784 - val_accuracy: 0.9726 - val_loss: 0.0785\n",
            "Epoch 11/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9696 - loss: 0.0780 - val_accuracy: 0.9770 - val_loss: 0.0753\n",
            "Epoch 12/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9718 - loss: 0.0727 - val_accuracy: 0.9750 - val_loss: 0.0745\n",
            "Epoch 13/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9717 - loss: 0.0734 - val_accuracy: 0.9737 - val_loss: 0.0752\n",
            "Epoch 14/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9771 - loss: 0.0659 - val_accuracy: 0.9750 - val_loss: 0.0703\n",
            "Epoch 15/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9755 - loss: 0.0621 - val_accuracy: 0.9739 - val_loss: 0.0709\n",
            "Epoch 16/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9747 - loss: 0.0656 - val_accuracy: 0.9753 - val_loss: 0.0694\n",
            "Epoch 17/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9781 - loss: 0.0581 - val_accuracy: 0.9764 - val_loss: 0.0700\n",
            "Epoch 18/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9775 - loss: 0.0591 - val_accuracy: 0.9748 - val_loss: 0.0709\n",
            "Epoch 19/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9744 - loss: 0.0643 - val_accuracy: 0.9767 - val_loss: 0.0669\n",
            "Epoch 20/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9767 - loss: 0.0568 - val_accuracy: 0.9745 - val_loss: 0.0699\n",
            "Epoch 21/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9770 - loss: 0.0570 - val_accuracy: 0.9798 - val_loss: 0.0653\n",
            "Epoch 22/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9778 - loss: 0.0597 - val_accuracy: 0.9789 - val_loss: 0.0689\n",
            "Epoch 23/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9788 - loss: 0.0547 - val_accuracy: 0.9800 - val_loss: 0.0680\n",
            "Epoch 24/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9792 - loss: 0.0526 - val_accuracy: 0.9803 - val_loss: 0.0653\n",
            "Epoch 25/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9754 - loss: 0.0735 - val_accuracy: 0.9789 - val_loss: 0.0680\n",
            "Epoch 26/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9778 - loss: 0.0580 - val_accuracy: 0.9770 - val_loss: 0.0697\n",
            "Epoch 27/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9811 - loss: 0.0554 - val_accuracy: 0.9759 - val_loss: 0.0660\n",
            "Epoch 28/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9790 - loss: 0.0500 - val_accuracy: 0.9820 - val_loss: 0.0655\n",
            "Epoch 29/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9803 - loss: 0.0483 - val_accuracy: 0.9809 - val_loss: 0.0662\n",
            "Epoch 30/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9802 - loss: 0.0502 - val_accuracy: 0.9811 - val_loss: 0.0684\n",
            "Epoch 31/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9800 - loss: 0.0492 - val_accuracy: 0.9820 - val_loss: 0.0681\n",
            "Epoch 32/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9788 - loss: 0.0573 - val_accuracy: 0.9817 - val_loss: 0.0651\n",
            "Epoch 33/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9796 - loss: 0.0556 - val_accuracy: 0.9811 - val_loss: 0.0658\n",
            "Epoch 34/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9828 - loss: 0.0471 - val_accuracy: 0.9798 - val_loss: 0.0659\n",
            "Epoch 35/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9809 - loss: 0.0458 - val_accuracy: 0.9820 - val_loss: 0.0650\n",
            "Epoch 36/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9815 - loss: 0.0471 - val_accuracy: 0.9806 - val_loss: 0.0664\n",
            "Epoch 37/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9804 - loss: 0.0513 - val_accuracy: 0.9806 - val_loss: 0.0662\n",
            "Epoch 38/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9818 - loss: 0.0464 - val_accuracy: 0.9806 - val_loss: 0.0666\n",
            "Epoch 39/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9814 - loss: 0.0485 - val_accuracy: 0.9823 - val_loss: 0.0639\n",
            "Epoch 40/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9817 - loss: 0.0474 - val_accuracy: 0.9806 - val_loss: 0.0648\n",
            "Epoch 41/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9811 - loss: 0.0475 - val_accuracy: 0.9811 - val_loss: 0.0660\n",
            "Epoch 42/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9805 - loss: 0.0471 - val_accuracy: 0.9820 - val_loss: 0.0694\n",
            "Epoch 43/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9830 - loss: 0.0449 - val_accuracy: 0.9817 - val_loss: 0.0653\n",
            "Epoch 44/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9802 - loss: 0.0487 - val_accuracy: 0.9811 - val_loss: 0.0691\n",
            "Epoch 45/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9804 - loss: 0.0503 - val_accuracy: 0.9820 - val_loss: 0.0716\n",
            "Epoch 46/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9827 - loss: 0.0417 - val_accuracy: 0.9811 - val_loss: 0.0727\n",
            "Epoch 47/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9812 - loss: 0.0450 - val_accuracy: 0.9803 - val_loss: 0.0741\n",
            "Epoch 48/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9821 - loss: 0.0451 - val_accuracy: 0.9814 - val_loss: 0.0675\n",
            "Epoch 49/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9807 - loss: 0.0484 - val_accuracy: 0.9806 - val_loss: 0.0703\n",
            "Epoch 50/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9827 - loss: 0.0468 - val_accuracy: 0.9823 - val_loss: 0.0698\n",
            "Epoch 51/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9812 - loss: 0.0444 - val_accuracy: 0.9814 - val_loss: 0.0758\n",
            "Epoch 52/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9826 - loss: 0.0443 - val_accuracy: 0.9809 - val_loss: 0.0726\n",
            "Epoch 53/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9822 - loss: 0.0433 - val_accuracy: 0.9811 - val_loss: 0.0703\n",
            "Epoch 54/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9816 - loss: 0.0435 - val_accuracy: 0.9823 - val_loss: 0.0723\n",
            "Epoch 55/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9801 - loss: 0.0473 - val_accuracy: 0.9817 - val_loss: 0.0737\n",
            "Epoch 56/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9840 - loss: 0.0427 - val_accuracy: 0.9800 - val_loss: 0.0704\n",
            "Epoch 57/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9839 - loss: 0.0399 - val_accuracy: 0.9811 - val_loss: 0.0636\n",
            "Epoch 58/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9842 - loss: 0.0412 - val_accuracy: 0.9809 - val_loss: 0.0665\n",
            "Epoch 59/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9831 - loss: 0.0429 - val_accuracy: 0.9814 - val_loss: 0.0654\n",
            "Epoch 60/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9805 - loss: 0.0435 - val_accuracy: 0.9817 - val_loss: 0.0657\n",
            "Epoch 61/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9822 - loss: 0.0435 - val_accuracy: 0.9820 - val_loss: 0.0660\n",
            "Epoch 62/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9839 - loss: 0.0409 - val_accuracy: 0.9809 - val_loss: 0.0675\n",
            "Epoch 63/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9851 - loss: 0.0399 - val_accuracy: 0.9820 - val_loss: 0.0704\n",
            "Epoch 64/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9837 - loss: 0.0397 - val_accuracy: 0.9809 - val_loss: 0.0714\n",
            "Epoch 65/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9852 - loss: 0.0414 - val_accuracy: 0.9809 - val_loss: 0.0704\n",
            "Epoch 66/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9834 - loss: 0.0400 - val_accuracy: 0.9825 - val_loss: 0.0710\n",
            "Epoch 67/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9841 - loss: 0.0389 - val_accuracy: 0.9823 - val_loss: 0.0658\n",
            "Epoch 68/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9845 - loss: 0.0425 - val_accuracy: 0.9823 - val_loss: 0.0799\n",
            "Epoch 69/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9823 - loss: 0.0417 - val_accuracy: 0.9817 - val_loss: 0.0763\n",
            "Epoch 70/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9840 - loss: 0.0430 - val_accuracy: 0.9820 - val_loss: 0.0694\n",
            "Epoch 71/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9852 - loss: 0.0397 - val_accuracy: 0.9814 - val_loss: 0.0694\n",
            "Epoch 72/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9810 - loss: 0.0460 - val_accuracy: 0.9817 - val_loss: 0.0657\n",
            "Epoch 73/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9850 - loss: 0.0382 - val_accuracy: 0.9809 - val_loss: 0.0660\n",
            "Epoch 74/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9830 - loss: 0.0406 - val_accuracy: 0.9814 - val_loss: 0.0700\n",
            "Epoch 75/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9828 - loss: 0.0434 - val_accuracy: 0.9814 - val_loss: 0.0704\n",
            "Epoch 76/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9841 - loss: 0.0388 - val_accuracy: 0.9820 - val_loss: 0.0693\n",
            "Epoch 77/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9832 - loss: 0.0508 - val_accuracy: 0.9823 - val_loss: 0.0698\n",
            "Epoch 78/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9823 - loss: 0.0434 - val_accuracy: 0.9823 - val_loss: 0.0715\n",
            "Epoch 79/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9836 - loss: 0.0400 - val_accuracy: 0.9820 - val_loss: 0.0753\n",
            "Epoch 80/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9810 - loss: 0.0441 - val_accuracy: 0.9817 - val_loss: 0.0727\n",
            "Epoch 81/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9851 - loss: 0.0411 - val_accuracy: 0.9823 - val_loss: 0.0700\n",
            "Epoch 82/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9843 - loss: 0.0379 - val_accuracy: 0.9823 - val_loss: 0.0692\n",
            "Epoch 83/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9840 - loss: 0.0404 - val_accuracy: 0.9803 - val_loss: 0.0792\n",
            "Epoch 84/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9851 - loss: 0.0365 - val_accuracy: 0.9814 - val_loss: 0.0778\n",
            "Epoch 85/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9845 - loss: 0.0414 - val_accuracy: 0.9811 - val_loss: 0.0774\n",
            "Epoch 86/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9855 - loss: 0.0418 - val_accuracy: 0.9823 - val_loss: 0.0721\n",
            "Epoch 87/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9837 - loss: 0.0416 - val_accuracy: 0.9817 - val_loss: 0.0872\n",
            "Epoch 88/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9831 - loss: 0.0420 - val_accuracy: 0.9809 - val_loss: 0.0754\n",
            "Epoch 89/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9855 - loss: 0.0411 - val_accuracy: 0.9814 - val_loss: 0.0742\n",
            "Epoch 90/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9871 - loss: 0.0356 - val_accuracy: 0.9823 - val_loss: 0.0708\n",
            "Epoch 91/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9833 - loss: 0.0364 - val_accuracy: 0.9811 - val_loss: 0.0737\n",
            "Epoch 92/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9849 - loss: 0.0384 - val_accuracy: 0.9820 - val_loss: 0.0780\n",
            "Epoch 93/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9845 - loss: 0.0410 - val_accuracy: 0.9817 - val_loss: 0.0839\n",
            "Epoch 94/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9830 - loss: 0.0404 - val_accuracy: 0.9823 - val_loss: 0.0712\n",
            "Epoch 95/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9859 - loss: 0.0394 - val_accuracy: 0.9823 - val_loss: 0.0734\n",
            "Epoch 96/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9845 - loss: 0.0391 - val_accuracy: 0.9809 - val_loss: 0.0751\n",
            "Epoch 97/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9873 - loss: 0.0342 - val_accuracy: 0.9834 - val_loss: 0.0727\n",
            "Epoch 98/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9840 - loss: 0.0413 - val_accuracy: 0.9825 - val_loss: 0.0746\n",
            "Epoch 99/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9847 - loss: 0.0378 - val_accuracy: 0.9820 - val_loss: 0.0751\n",
            "Epoch 100/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9841 - loss: 0.0396 - val_accuracy: 0.9825 - val_loss: 0.0779\n",
            "Epoch 101/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9840 - loss: 0.0401 - val_accuracy: 0.9831 - val_loss: 0.0790\n",
            "Epoch 102/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9849 - loss: 0.0362 - val_accuracy: 0.9825 - val_loss: 0.0769\n",
            "Epoch 103/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9862 - loss: 0.0351 - val_accuracy: 0.9836 - val_loss: 0.0756\n",
            "Epoch 104/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9834 - loss: 0.0410 - val_accuracy: 0.9831 - val_loss: 0.0818\n",
            "Epoch 105/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9852 - loss: 0.0374 - val_accuracy: 0.9825 - val_loss: 0.0769\n",
            "Epoch 106/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9836 - loss: 0.0385 - val_accuracy: 0.9834 - val_loss: 0.0786\n",
            "Epoch 107/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9853 - loss: 0.0357 - val_accuracy: 0.9820 - val_loss: 0.0791\n",
            "Epoch 108/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9872 - loss: 0.0319 - val_accuracy: 0.9817 - val_loss: 0.0811\n",
            "Epoch 109/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9842 - loss: 0.0390 - val_accuracy: 0.9825 - val_loss: 0.0801\n",
            "Epoch 110/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9837 - loss: 0.0412 - val_accuracy: 0.9823 - val_loss: 0.0965\n",
            "Epoch 111/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9859 - loss: 0.0330 - val_accuracy: 0.9823 - val_loss: 0.0925\n",
            "Epoch 112/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9851 - loss: 0.0346 - val_accuracy: 0.9817 - val_loss: 0.0985\n",
            "Epoch 113/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9844 - loss: 0.0362 - val_accuracy: 0.9820 - val_loss: 0.0899\n",
            "Epoch 114/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9837 - loss: 0.0394 - val_accuracy: 0.9823 - val_loss: 0.0887\n",
            "Epoch 115/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9859 - loss: 0.0365 - val_accuracy: 0.9817 - val_loss: 0.0865\n",
            "Epoch 116/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9844 - loss: 0.0367 - val_accuracy: 0.9814 - val_loss: 0.0909\n",
            "Epoch 117/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9847 - loss: 0.0384 - val_accuracy: 0.9823 - val_loss: 0.0960\n",
            "Epoch 118/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9853 - loss: 0.0363 - val_accuracy: 0.9809 - val_loss: 0.0967\n",
            "Epoch 119/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9838 - loss: 0.0411 - val_accuracy: 0.9825 - val_loss: 0.0895\n",
            "Epoch 120/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9840 - loss: 0.0361 - val_accuracy: 0.9820 - val_loss: 0.0898\n",
            "Epoch 121/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9836 - loss: 0.0410 - val_accuracy: 0.9823 - val_loss: 0.0931\n",
            "Epoch 122/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9852 - loss: 0.0369 - val_accuracy: 0.9834 - val_loss: 0.0878\n",
            "Epoch 123/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9851 - loss: 0.0376 - val_accuracy: 0.9825 - val_loss: 0.0873\n",
            "Epoch 124/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9835 - loss: 0.0412 - val_accuracy: 0.9823 - val_loss: 0.0895\n",
            "Epoch 125/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9845 - loss: 0.0355 - val_accuracy: 0.9823 - val_loss: 0.0873\n",
            "Epoch 126/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9857 - loss: 0.0382 - val_accuracy: 0.9828 - val_loss: 0.0878\n",
            "Epoch 127/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9858 - loss: 0.0378 - val_accuracy: 0.9811 - val_loss: 0.0940\n",
            "Epoch 128/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9860 - loss: 0.0352 - val_accuracy: 0.9825 - val_loss: 0.0866\n",
            "Epoch 129/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9841 - loss: 0.0360 - val_accuracy: 0.9828 - val_loss: 0.0859\n",
            "Epoch 130/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9861 - loss: 0.0351 - val_accuracy: 0.9836 - val_loss: 0.0849\n",
            "Epoch 131/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9851 - loss: 0.0378 - val_accuracy: 0.9825 - val_loss: 0.0890\n",
            "Epoch 132/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9866 - loss: 0.0327 - val_accuracy: 0.9828 - val_loss: 0.0742\n",
            "Epoch 133/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9834 - loss: 0.0409 - val_accuracy: 0.9839 - val_loss: 0.0800\n",
            "Epoch 134/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9849 - loss: 0.0343 - val_accuracy: 0.9828 - val_loss: 0.0798\n",
            "Epoch 135/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9854 - loss: 0.0386 - val_accuracy: 0.9817 - val_loss: 0.0828\n",
            "Epoch 136/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9867 - loss: 0.0379 - val_accuracy: 0.9831 - val_loss: 0.0878\n",
            "Epoch 137/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9869 - loss: 0.0362 - val_accuracy: 0.9831 - val_loss: 0.0881\n",
            "Epoch 138/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9857 - loss: 0.0351 - val_accuracy: 0.9836 - val_loss: 0.0965\n",
            "Epoch 139/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9834 - loss: 0.0383 - val_accuracy: 0.9823 - val_loss: 0.0925\n",
            "Epoch 140/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9844 - loss: 0.0339 - val_accuracy: 0.9828 - val_loss: 0.0914\n",
            "Epoch 141/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9866 - loss: 0.0351 - val_accuracy: 0.9823 - val_loss: 0.0943\n",
            "Epoch 142/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9848 - loss: 0.0354 - val_accuracy: 0.9823 - val_loss: 0.0828\n",
            "Epoch 143/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9859 - loss: 0.0338 - val_accuracy: 0.9825 - val_loss: 0.0782\n",
            "Epoch 144/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9859 - loss: 0.0363 - val_accuracy: 0.9836 - val_loss: 0.0769\n",
            "Epoch 145/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9854 - loss: 0.0361 - val_accuracy: 0.9820 - val_loss: 0.0788\n",
            "Epoch 146/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9852 - loss: 0.0348 - val_accuracy: 0.9831 - val_loss: 0.0824\n",
            "Epoch 147/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9848 - loss: 0.0364 - val_accuracy: 0.9823 - val_loss: 0.0864\n",
            "Epoch 148/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9835 - loss: 0.0386 - val_accuracy: 0.9828 - val_loss: 0.0853\n",
            "Epoch 149/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9851 - loss: 0.0377 - val_accuracy: 0.9825 - val_loss: 0.0878\n",
            "Epoch 150/150\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9858 - loss: 0.0353 - val_accuracy: 0.9831 - val_loss: 0.0859\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ DL Model, Scaler, and Label Encoder saved!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import joblib\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv('/content/kdd_test.csv')  # Or use your full training dataset\n",
        "df.columns = [f\"col_{i}\" for i in range(len(df.columns)-1)] + ['label']\n",
        "\n",
        "# Save a copy of attack type\n",
        "df['attack_type'] = df['label']\n",
        "\n",
        "# Encode categorical features\n",
        "for col in df.select_dtypes(include='object').columns:\n",
        "    if col != 'label':\n",
        "        le = LabelEncoder()\n",
        "        df[col] = le.fit_transform(df[col])\n",
        "\n",
        "# Encode label as attack or normal\n",
        "df['label'] = df['label'].apply(lambda x: 'normal' if 'normal' in x else 'attack')\n",
        "\n",
        "# Label encode the target column\n",
        "label_encoder = LabelEncoder()\n",
        "df['label'] = label_encoder.fit_transform(df['label'])  # normal=1, attack=0\n",
        "\n",
        "# Features and target\n",
        "X = df.drop(['label', 'attack_type'], axis=1)\n",
        "y = df['label']\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Define DL model\n",
        "model = Sequential([\n",
        "    Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
        "    Dropout(0.3),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dropout(0.2),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train_scaled, y_train, epochs=150, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Save model and encoders\n",
        "model.save('dl_model.h5')\n",
        "joblib.dump(scaler, 'scaler.pkl')\n",
        "joblib.dump(label_encoder, 'label_encoder.pkl')\n",
        "\n",
        "print(\"✅ DL Model, Scaler, and Label Encoder saved!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t3JLR_9qr8wz",
        "outputId": "793f2f83-37da-4026-b13d-6f1246ae5eab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step\n",
            "\n",
            "🔍 DL Predictions on 3 Random Samples:\n",
            "Sample 1: Normal | Attack Type: normal\n",
            "Sample 2: Normal | Attack Type: normal\n",
            "Sample 3:  Attack Detected | Attack Type: warezclient\n",
            "Sample 4:  Attack Detected | Attack Type: neptune\n",
            "Sample 5: Normal | Attack Type: normal\n",
            "Sample 6: Normal | Attack Type: normal\n",
            "Sample 7: Normal | Attack Type: normal\n",
            "Sample 8: Normal | Attack Type: normal\n",
            "Sample 9:  Attack Detected | Attack Type: smurf\n",
            "Sample 10:  Attack Detected | Attack Type: neptune\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "from tensorflow.keras.models import load_model\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Load the testing dataset\n",
        "df = pd.read_csv('/content/testing_dataset.csv')\n",
        "df.columns = [f\"col_{i}\" for i in range(len(df.columns)-1)] + ['label']\n",
        "\n",
        "# Save original attack type names\n",
        "original_attacks = df['label'].values.copy()\n",
        "\n",
        "# Encode categorical columns (not 'label')\n",
        "for col in df.select_dtypes(include='object').columns:\n",
        "    if col != 'label':\n",
        "        le = LabelEncoder()\n",
        "        df[col] = le.fit_transform(df[col])\n",
        "\n",
        "# Binary classification label\n",
        "df['label'] = df['label'].apply(lambda x: 'normal' if 'normal' in x else 'attack')\n",
        "\n",
        "# Load saved encoders and model\n",
        "label_encoder = joblib.load('label_encoder.pkl')\n",
        "scaler = joblib.load('scaler.pkl')\n",
        "dl_model = load_model('dl_model.h5')  # Change name if yours is different\n",
        "\n",
        "# Encode label\n",
        "df['label'] = label_encoder.transform(df['label'])\n",
        "\n",
        "# Prepare features\n",
        "X_test = df.drop(['label'], axis=1)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Pick 3 random test samples\n",
        "sample_df = df.sample(n=10, random_state=42)\n",
        "sample_indices = sample_df.index\n",
        "sample_X_scaled = X_test_scaled[sample_indices]\n",
        "sample_attack_names = original_attacks[sample_indices]\n",
        "\n",
        "# Predict with DL model\n",
        "sample_preds_probs = dl_model.predict(sample_X_scaled)\n",
        "sample_preds = (sample_preds_probs > 0.5).astype(int).flatten()\n",
        "\n",
        "# 🖨️ Show output\n",
        "print(\"\\n🔍 DL Predictions on 3 Random Samples:\")\n",
        "for i, (pred, attack_name) in enumerate(zip(sample_preds, sample_attack_names)):\n",
        "    status = \"Normal\" if pred == 1 else \" Attack Detected\"\n",
        "    print(f\"Sample {i+1}: {status} | Attack Type: {attack_name}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}